{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb83954-7e7d-4895-86da-16695f613960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import VideoLlavaForConditionalGeneration, VideoLlavaProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff3c4d-048e-4d4d-a91f-554f9332b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "print(os.getenv(\"CONDA_DEFAULT_ENV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07691f-e70e-4805-8967-c104f865f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`list[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01334eb1-4942-4fe0-81f3-963116814d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model in half-precision\n",
    "model = VideoLlavaForConditionalGeneration.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "processor = VideoLlavaProcessor.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc95ac-71eb-4963-a6a9-cb5b457a2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499d96b-3be3-4099-a540-c585c673433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video as an np.arrau, sampling uniformly 8 frames\n",
    "from huggingface_hub import hf_hub_download\n",
    "# video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename='/home/aritrad/video-study/INTRO.mp4', repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c2497-6678-45ab-a0d3-fefeb237d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/home/aritrad/MSR-Project/samples/12min-video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5efc95-d05c-4476-a33a-a76ec34532f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = av.open(video_path)\n",
    "total_frames = container.streams.video[0].frames\n",
    "indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n",
    "video = read_video_pyav(container, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0df7c6-7849-4b42-b916-84916650ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'When spinlocks should be used'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faeea6e-557f-40d6-816a-b2a9c00e07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better results, we recommend to prompt the model in the following format\n",
    "prompt = f\"USER: <video>\\n{question}? ASSISTANT:\"\n",
    "inputs = processor(text=prompt, videos=video, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs, max_new_tokens=256)\n",
    "generated_text = processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13717c66-f28c-4057-ba79-aa89e5df2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text[0].split('ASSISTANT:')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b46e54-1389-46df-823e-3bd08977f667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d175bcc-4303-4436-9407-824dcc39fd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d97e0-d662-4136-9b21-cd0553df9a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7adda2-9dfe-4e7a-8542-57303cf8ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better results, we recommend to prompt the model in the following format\n",
    "prompt = \"USER: <video>\\nWhat does the standish group report says? ASSISTANT:\"\n",
    "inputs = processor(text=prompt, videos=video, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs, max_new_tokens=256)\n",
    "processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1fa32-e7f7-457e-8b0c-39805ecb0285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086608a-a917-400c-b47f-febbf5786cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better results, we recommend to prompt the model in the following format\n",
    "prompt = \"USER: <video>\\nWhat is the IEEE definition of software engineering discussed in the video? ASSISTANT:\"\n",
    "inputs = processor(text=prompt, videos=video, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs, max_new_tokens=256)\n",
    "processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb29f87-1465-4ede-bdfa-648ecbc13375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13a673-7a9f-4447-bb78-b42420da2157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785121b8-59ba-4eb6-9c07-5576ca86d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better results, we recommend to prompt the model in the following format\n",
    "prompt = \"USER: <video>\\Which factors are contributing to the software crisis? ASSISTANT:\"\n",
    "inputs = processor(text=prompt, videos=video, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs, max_new_tokens=256)\n",
    "processor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9330b47-814c-4698-bb6a-21d81fc5f6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
